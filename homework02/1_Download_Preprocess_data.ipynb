{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/maschu09/mless/blob/main/time_series_forecasting/1_Download_Preprocess_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"],"id":"view-in-github"},{"cell_type":"markdown","id":"93fb8933","metadata":{"id":"93fb8933"},"source":["# Data download and preparation\n","\n","In the following, we will set-up a typical data preprocessing workflow for (environmental) timeseries data. It is quite common that such data can be obtained via a web interface (REST API) and that the output from this API requires substantial reformatting and rearranging before the data can be imported into analysis or forecasting models. Typical issues encountered include:\n","* time series at different stations (and for different parameters) vary in length\n","* timeseries have some or many missing values, which are either absent from the data series or encoded as special values\n","* data vary in quality (some datasets may have jumps or awkward \"features\" that cannot be explained by natural phenomena)\n","* metadata to inform the data selection are missing ort difficult to access/process\n","\n","In this notebook, we try to keep things relatively simple and straightforward while providing a set of tools that can also be used in more meaningful applications.\n","\n","The default use case on which this notebook builds is to extract timeseries of the variable \"temperature\" from a handful of measurement locations, store intermediate results to avoid repeated downloads, and package the data into a single CSV file for input in the statistical analyses and ML models shown in the subsequent notebooks. The code will also run if you extract several variables at once or increase the number of stations. However, for massive data downloads, you will need to rewrite the code to be more efficient and add some monitoring of your downloads.\n","\n","> Please note: In case of runtime loss or a need to run any segmented sections of the code make sure to run all the housekeeping cells before it\n","\n","\n","\n","\n"]},{"cell_type":"markdown","id":"13766b33","metadata":{"id":"13766b33"},"source":["## Initial Setup and Data download\n","> This section downloads example data from TOAR for 5 stations in Germany. Refer to [TOAR Quick UserGuide](https://toar-data.fz-juelich.de/sphinx/TOAR_UG_Vol02_Quick_Start/build/html/examples.html) examples to better understand data structuring in TOAR that is used in the below snippet to download examples.\n","\n","<p align=\"center\">\n","  <img src=\"https://github.com/maschu09/mless/blob/main/time_series_forecasting/TOARFetchingBlockDiag.png?raw=1\" alt=\"TOAR Block Diag\" width=\"600\"/>\n","</p>\n"]},{"cell_type":"markdown","id":"49eb9d93","metadata":{"id":"49eb9d93"},"source":["### Housekeeping: Initial setup, declarations and method definitions\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"cb98c436","metadata":{"id":"cb98c436","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750703044906,"user_tz":-120,"elapsed":14661,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}},"outputId":"347c0c79-9753-4ed0-c1a5-4f7663cfb5a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}],"source":["# Most notebook servers like google collab should have these packages pre-installed\n","# In such cases this is just a sanity check\n","!pip install pandas numpy requests tensorflow"]},{"cell_type":"code","execution_count":1,"id":"b4eba776","metadata":{"id":"b4eba776","executionInfo":{"status":"ok","timestamp":1750782660448,"user_tz":-120,"elapsed":706,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[],"source":["import requests\n","import json\n","import pandas as pd\n","import os\n","import csv\n","from datetime import datetime\n"]},{"cell_type":"markdown","id":"46de7d59","metadata":{"id":"46de7d59"},"source":["#### Alternative"]},{"cell_type":"code","execution_count":2,"id":"fc809476","metadata":{"id":"fc809476","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750782696509,"user_tz":-120,"elapsed":34862,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}},"outputId":"2bd9efe1-8c96-41ee-ade2-957b5ac719ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount google drive when working in colab\n","hasCOLAB = 'google.colab' in str(get_ipython()) if hasattr(__builtins__,'__IPYTHON__') else False\n","if hasCOLAB:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  BASEPATH = '/content/drive/MyDrive'\n","else:\n","  BASEPATH = '.'"]},{"cell_type":"code","execution_count":3,"id":"100829ff","metadata":{"id":"100829ff","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750782701057,"user_tz":-120,"elapsed":419,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}},"outputId":"f701014d-668b-4c21-f59a-c68e1e705a03"},"outputs":[{"output_type":"stream","name":"stdout","text":["'023 PowerPoint DE.gslides'\t  'Copy of autodone Usage.gsheet'\n","'023 PowerPoint EN.gslides'\t  'CV Proposal.gdoc'\n"," 101_food_classes_10_percent\t  'Fahren in die urlaub mit freunde.gsheet'\n"," AESDP.gslides\t\t\t   fine_tuning_first_30\n","'AESDP - Pie chart 1 (1).gsheet'   folds\n","'AESDP - Pie chart 1 (2).gsheet'  'Food Vision Big: Data + Models'\n","'AESDP - Pie chart 1.gsheet'\t  'GameDev Gruppe F.gslides'\n"," assignment_1.ipynb\t\t  'gamedev presentation 2.gslides'\n"," assignment4.ipynb\t\t  'Just send it'\n","'Blogpost DH.gdoc'\t\t   results.rar\n","'Colab Notebooks'\t\t   timeseries_data\n","'Computer Vision Proposal.gdoc'    time_series_forecasting\n"]}],"source":["!ls drive/MyDrive"]},{"cell_type":"code","execution_count":4,"id":"e51ceddc","metadata":{"id":"e51ceddc","executionInfo":{"status":"ok","timestamp":1750782704032,"user_tz":-120,"elapsed":14,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[],"source":["# Global constants\n","TIMESERIES_DATA_DIR = BASEPATH + \"/timeseries_data/\"\n","TIMESERIES_CSV_DIR = os.path.join(TIMESERIES_DATA_DIR, \"toar_csv_timeseries\")\n","TIMESERIES_ID_FILE = os.path.join(TIMESERIES_DATA_DIR, \"timeseriesIDs.json\")\n","MIN_FILE_SIZE_BYTES = 100\n","group_columns = ['station_code', 'latitude', 'longitude']\n","\n","os.makedirs(TIMESERIES_DATA_DIR, exist_ok=True)\n","os.makedirs(TIMESERIES_CSV_DIR, exist_ok=True)"]},{"cell_type":"markdown","id":"46af26a1","metadata":{"id":"46af26a1"},"source":["### Custom data selection for experiments\n","\n","The station codes in the example snippet below are checked for a common daterange for the chosen variables and offer reasonably complete timeseries. If you prefer to experiment with other datasets, consult the documentation on the [Search API](https://toar-data.fz-juelich.de/api/v2/#search-combined-endpoint-of-stations-and-timeseries).\n","\n","😈 **Question 1:** What are common reasons for gaps in observational data records, such as from TOAR?\n","\n","**Answer**  \n","Two common ones are maintenance and malfunction of the underlying sensors. Another not so commong reason could be data that didnt pass quality control or sanity checks and had to be discarded.\n"]},{"cell_type":"code","execution_count":5,"id":"9663fef6","metadata":{"id":"9663fef6","executionInfo":{"status":"ok","timestamp":1750783017020,"user_tz":-120,"elapsed":11,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[],"source":["# German stations with good data coverage\n","station_codes = [\"DENW094\", \"DEBW073\",\"DEHE020\"]\n","variable_columns = [\"temp\"]\n","# station_codes = [\"DENW094\"]\n","# variable_columns = [\"no2\", \"temp\", \"o3\", \"no\", \"press\"]\n"]},{"cell_type":"markdown","id":"70d99569","metadata":{"id":"70d99569"},"source":["😈 **Task 1:** Explore the `station_codes` variable and try changing the station(s) to a different region.\n","\n","Below methods each have appropriate documentation and comments to illustrate the logical flow *(they are placed with enough safeguards against both the API and optimized to avoid re-downloads when interupted during partial downloads to accomodate any loss of runtime on platforms like google colab)* and briefly described here for ease of use\n","\n","😈 **Task 2:** Inspect the function `pivot_handle()`. What does it return, and why is pivoting important for time series analysis?\n"]},{"cell_type":"code","execution_count":6,"id":"ef2eebb7","metadata":{"id":"ef2eebb7","executionInfo":{"status":"ok","timestamp":1750783018996,"user_tz":-120,"elapsed":17,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[],"source":["def load_existing_timeseries_ids():\n","    \"\"\"\n","    Load existing timeseries IDs from a JSON file.\n","\n","    Returns:\n","        dict: A dictionary containing stored timeseries metadata.\n","    \"\"\"\n","    return json.load(open(TIMESERIES_ID_FILE, 'r')) if os.path.exists(TIMESERIES_ID_FILE) else {}\n","\n","def save_timeseries_ids(timeseries_data):\n","    \"\"\"\n","    Save timeseries metadata to a JSON file.\n","\n","    Args:\n","        timeseries_data (dict): A dictionary containing timeseries metadata.\n","    \"\"\"\n","    json.dump(timeseries_data, open(TIMESERIES_ID_FILE, 'w'), indent=4)\n","\n","def fetch_timeseries_data(station_codes, existing_timeseries, variable_columns):\n","    \"\"\"\n","    Fetch timeseries metadata for given station codes, filtering by specified variables.\n","\n","    Args:\n","        station_codes (list): List of station codes to fetch data for.\n","        existing_timeseries (dict): Dictionary of previously fetched timeseries metadata.\n","        variable_columns (list): List of variable names to retain.\n","\n","    Returns:\n","        dict: Updated dictionary containing filtered timeseries metadata.\n","    \"\"\"\n","    base_url = \"http://toar-data.fz-juelich.de/api/v2/search/?codes=\"\n","    unique_entries = existing_timeseries.copy()\n","    processed_station_codes = {details['station_code'] for details in existing_timeseries.values()}\n","\n","    for code in station_codes:\n","        if code in processed_station_codes:\n","            print(f\"\\t\\tStation {code} is already processed, skipping.\")\n","            continue\n","\n","        response = requests.get(base_url + code, timeout=1000)\n","        if response.status_code == 200:\n","            for entry in response.json():\n","                if (variable_name := entry.get('variable', {}).get('name')) in variable_columns:\n","                    timeseries_id = entry.get('id')\n","                    if timeseries_id not in unique_entries:\n","                        unique_entries[timeseries_id] = {\n","                            'data_start_date': entry.get('data_start_date'),\n","                            'data_end_date': entry.get('data_end_date'),\n","                            'variable_name': variable_name,\n","                            'station_code': code,\n","                            'latitude': entry.get('station', {}).get('coordinates', {}).get('lat'),\n","                            'longitude': entry.get('station', {}).get('coordinates', {}).get('lng'),\n","                        }\n","        else:\n","            print(f\"\\t\\tFailed to fetch data for station {code}. Status code: {response.status_code}\")\n","    return unique_entries\n","\n","def pivot_handle(dfs, metadata_columns, variable_columns):\n","    \"\"\"\n","    Pivot and structure the timeseries dataframe for sequential data analysis.\n","\n","    Args:\n","        dfs (pd.DataFrame): Dataframe containing timeseries data.\n","        metadata_columns (list): List of metadata column names.\n","        variable_columns (list): List of variable names to include.\n","\n","    Returns:\n","        pd.DataFrame: Processed dataframe with pivoted structure.\n","    \"\"\"\n","    pivot_df = dfs.pivot_table(index='datetime', columns='variable_name', values='value', aggfunc='mean')\n","    pivot_df.reset_index(inplace=True)\n","\n","    print(f\"Station {dfs['station_code'].unique()} min time: {dfs['datetime'].min()}, max time: {dfs['datetime'].max()}, hours between: {(dfs['datetime'].max() - dfs['datetime'].min()) / pd.Timedelta(hours=1):.2f}\")\n","    reference_index = pd.date_range(start=dfs['datetime'].min(), end=dfs['datetime'].max(), freq=\"h\", tz=\"UTC\")\n","    reference_df = pd.DataFrame({'datetime': reference_index})\n","\n","    pivot_df_ = reference_df.merge(pivot_df, on='datetime', how='left')\n","\n","    for col in metadata_columns:\n","        if dfs[col].notna().any():\n","            value = dfs[col].dropna().iloc[0]\n","            pivot_df_.insert(0, col, value)\n","        else:\n","            print(f\"Station {dfs['station_code'].unique()}: metadata {col} has no value\")\n","\n","    return pivot_df_\n","\n","def download_csv_data(timeseries_data, variable_columns):\n","    \"\"\"\n","    Download and process CSV data for each timeseries ID.\n","\n","    Args:\n","        timeseries_data (dict): Dictionary containing timeseries metadata.\n","        variable_columns (list): List of variable names to process.\n","\n","    Returns:\n","        pd.DataFrame: Combined dataframe of all timeseries data.\n","    \"\"\"\n","    dataframes = []\n","    metadata_columns = ['station_code', 'latitude', 'longitude']\n","\n","    for ts_id, details in timeseries_data.items():\n","        csv_path = os.path.join(TIMESERIES_CSV_DIR, f\"{ts_id}.csv\")\n","\n","        if os.path.exists(csv_path) and os.path.getsize(csv_path) > MIN_FILE_SIZE_BYTES:\n","            print(f\"\\tCSV already exists for timeseries ID {ts_id}, skipping download.\")\n","        else:\n","            print(f\"\\tDownloading data for timeseries ID {ts_id}\")\n","            url = f\"http://toar-data.fz-juelich.de/api/v2/data/timeseries/{ts_id}?format=csv\"\n","            try:\n","                response = requests.get(url, stream=True, timeout=1000)\n","                response.raise_for_status()\n","                with open(csv_path, 'wb') as file:\n","                    file.writelines(response.iter_content(chunk_size=8192))\n","                print(f\"\\t\\tRaw data CSV of {ts_id} saved: {csv_path}\")\n","            except requests.exceptions.RequestException as e:\n","                print(f\"\\t\\tFailed to download data for timeseries ID {ts_id}. Error: {e}\")\n","                continue\n","\n","        try:\n","            df = pd.read_csv(csv_path, skiprows=lambda i: i < next(i for i, line in enumerate(open(csv_path)) if line.startswith('datetime')), low_memory=False)\n","            df['datetime'] = pd.to_datetime(df['datetime'], format='mixed')\n","            df[['variable_name', 'station_code', 'latitude', 'longitude']] = details['variable_name'], details['station_code'], details['latitude'], details['longitude']\n","            print(f\"Dataframe for timeseries ID {ts_id} loaded successfully with shape {df.shape}\")\n","            dataframes.append(pivot_handle(df, metadata_columns, variable_columns))\n","        except (pd.errors.EmptyDataError, pd.errors.ParserError) as e:\n","            print(f\"\\tError processing CSV for timeseries ID {ts_id}: {e}\")\n","            continue\n","\n","    return pd.concat(dataframes, ignore_index=True).sort_values(by=['station_code', 'datetime']) if dataframes else pd.DataFrame()"]},{"cell_type":"markdown","id":"6dab0925","metadata":{"id":"6dab0925"},"source":["### Download via REST API\n","\n","😈 **Task 3:** Try downloading a different variable or add another pollutant (e.g., `so2`). What changes?\n"]},{"cell_type":"code","execution_count":7,"id":"5c3464c4","metadata":{"id":"5c3464c4","outputId":"5352d3d1-cded-4c03-90ac-a1d363a4cd2a","colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"status":"ok","timestamp":1750783778475,"user_tz":-120,"elapsed":755946,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\t\tStation DENW094 is already processed, skipping.\n","\t\tStation DEBW073 is already processed, skipping.\n","\t\tStation DEHE020 is already processed, skipping.\n","\t Number of time series meta data fetched : 3\n","\tDownloading data for timeseries ID 76\n","\t\tRaw data CSV of 76 saved: /content/drive/MyDrive/timeseries_data/toar_csv_timeseries/76.csv\n","Dataframe for timeseries ID 76 loaded successfully with shape (246484, 9)\n","Station ['DENW094'] min time: 1997-01-01 00:00:00+00:00, max time: 2025-06-24 11:00:00+00:00, hours between: 249635.00\n","\tCSV already exists for timeseries ID 22639, skipping download.\n","Dataframe for timeseries ID 22639 loaded successfully with shape (110890, 9)\n","Station ['DEBW073'] min time: 1997-01-01 00:00:00+00:00, max time: 2011-12-31 23:00:00+00:00, hours between: 131471.00\n","\tDownloading data for timeseries ID 18022\n","\t\tFailed to download data for timeseries ID 18022. Error: 502 Server Error: Bad Gateway for url: https://toar-data.fz-juelich.de/api/v2/data/timeseries/18022?format=csv\n","\t Total dataFrames processed : 381108 and shape of first dataframe (381108, 5).\n"]},{"output_type":"execute_result","data":{"text/plain":["        longitude   latitude station_code                  datetime  temp\n","249636   7.567796  47.819182      DEBW073 1997-01-01 00:00:00+00:00 -10.0\n","249637   7.567796  47.819182      DEBW073 1997-01-01 01:00:00+00:00 -11.0\n","249638   7.567796  47.819182      DEBW073 1997-01-01 02:00:00+00:00 -11.0\n","249639   7.567796  47.819182      DEBW073 1997-01-01 03:00:00+00:00 -12.0\n","249640   7.567796  47.819182      DEBW073 1997-01-01 04:00:00+00:00 -12.0"],"text/html":["\n","  <div id=\"df-971eff8b-e316-4815-aa77-3062956030e4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>station_code</th>\n","      <th>datetime</th>\n","      <th>temp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>249636</th>\n","      <td>7.567796</td>\n","      <td>47.819182</td>\n","      <td>DEBW073</td>\n","      <td>1997-01-01 00:00:00+00:00</td>\n","      <td>-10.0</td>\n","    </tr>\n","    <tr>\n","      <th>249637</th>\n","      <td>7.567796</td>\n","      <td>47.819182</td>\n","      <td>DEBW073</td>\n","      <td>1997-01-01 01:00:00+00:00</td>\n","      <td>-11.0</td>\n","    </tr>\n","    <tr>\n","      <th>249638</th>\n","      <td>7.567796</td>\n","      <td>47.819182</td>\n","      <td>DEBW073</td>\n","      <td>1997-01-01 02:00:00+00:00</td>\n","      <td>-11.0</td>\n","    </tr>\n","    <tr>\n","      <th>249639</th>\n","      <td>7.567796</td>\n","      <td>47.819182</td>\n","      <td>DEBW073</td>\n","      <td>1997-01-01 03:00:00+00:00</td>\n","      <td>-12.0</td>\n","    </tr>\n","    <tr>\n","      <th>249640</th>\n","      <td>7.567796</td>\n","      <td>47.819182</td>\n","      <td>DEBW073</td>\n","      <td>1997-01-01 04:00:00+00:00</td>\n","      <td>-12.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-971eff8b-e316-4815-aa77-3062956030e4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-971eff8b-e316-4815-aa77-3062956030e4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-971eff8b-e316-4815-aa77-3062956030e4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-68a430b7-50d7-4679-bbaa-02781d16decc\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68a430b7-50d7-4679-bbaa-02781d16decc')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-68a430b7-50d7-4679-bbaa-02781d16decc button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"dataframes"}},"metadata":{},"execution_count":7}],"source":["# Load existing timeseries IDs from json to skip calls to TOAR\n","existing_timeseries = load_existing_timeseries_ids()\n","\n","timeseries_data = fetch_timeseries_data(station_codes, existing_timeseries,variable_columns)\n","print(f\"\\t Number of time series meta data fetched : {len(timeseries_data)}\")\n","\n","# save existing timeseries IDs as json to reduce calls to TOAR in future\n","save_timeseries_ids(timeseries_data)\n","\n","dataframes = download_csv_data(timeseries_data,variable_columns)\n","print(f\"\\t Total dataFrames processed : {len(dataframes)} and shape of first dataframe {dataframes.shape}.\")\n","\n","dataframes.head()"]},{"cell_type":"markdown","id":"86c8d25f","metadata":{"id":"86c8d25f"},"source":["Most of the data in TOAR is observational data which has few or many data gaps. The \"temp\"(erature) data that you downloaded is actually from a model (ERA5 reanalysis) and should therefore not have any missing values (except if your requested daterange extends beyond the period for which we extracted ERA5 data).\n","\n","To demonstrate a more typical workflow of handling observational data, we will now inspect, interpolate, and remove missing data values. Note that the pivot routine above merged data from different variables together and introduced NaNs."]},{"cell_type":"markdown","id":"2588a2f2","metadata":{"id":"2588a2f2"},"source":["## Data handling (observational gaps)\n","\n","😈 **Task 4:** Insert some code to find out how many NaN values each variable in the dataset contains. Even better: try to generate a bargraph showing the number of instances with consecutive NaN values (1, 2, 3, ..., more than 10).\n","\n","To provide as much training data to ML models as possible, you typically want to fill gaps through interpolation. For environmental data, it is common practice to interpolate over up to 6 hours but not longer. In many cases, linear interpolation will work just fine.\n","\n","\n","😈 **Question 3:** Why is it acceptable to fill up to 6 missing hourly values in this dataset?\n","\n","😈 **Question 4:** Why do you need to interpolate at all? Wouldn't it be sufficient to randomly sample from the existing data?\n"]},{"cell_type":"code","execution_count":8,"id":"0237f955","metadata":{"id":"0237f955","executionInfo":{"status":"ok","timestamp":1750783897447,"user_tz":-120,"elapsed":46,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[],"source":["import numpy as np\n","def fill_six_nans(group):\n","    \"\"\"\n","    Fills up to six consecutive NaN values in a given pandas Series using linear interpolation\n","    if the NaNs are surrounded by valid values. If the NaNs are at the start, they are replaced\n","    with zeros, and if they are at the end, they are filled with the last known value.\n","\n","    Args:\n","        group (pd.Series): The input Series with potential NaN values.\n","\n","    Returns:\n","        pd.Series: A Series where up to six consecutive NaNs are interpolated, and longer NaN\n","        sequences are partially filled while preserving the original index.\n","    \"\"\"\n","    values = group.to_numpy()\n","    i = 0\n","    while i < len(values):\n","        if np.isnan(values[i]):\n","            start = i\n","            while i < len(values) and np.isnan(values[i]):\n","                i += 1\n","            end = min(i, start + 6)  # Limit to filling only 6 NaNs\n","\n","            if start > 0 and i < len(values):  # NaNs in the middle\n","                fill_values = np.linspace(values[start - 1], values[i], end - start + 2)[1:-1]\n","            elif start == 0:  # NaNs at the start\n","                fill_values = [0] * (end - start)\n","            elif i >= len(values):  # NaNs at the end\n","                fill_values = [values[start - 1]] * (end - start)\n","            values[start:end] = fill_values\n","        else:\n","            i += 1\n","    return pd.Series(values, index=group.index)"]},{"cell_type":"code","execution_count":9,"id":"d861e5dd","metadata":{"id":"d861e5dd","outputId":"28ca3583-19d2-4dce-84bb-875c9d599b4a","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1750783899015,"user_tz":-120,"elapsed":691,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["longitude           0\n","latitude            0\n","station_code        0\n","datetime            0\n","temp            21924\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>longitude</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>latitude</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>station_code</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>datetime</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>temp</th>\n","      <td>21924</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":9}],"source":["dataframes[variable_columns] = dataframes.groupby(group_columns)[variable_columns].transform(fill_six_nans)\n","dataframes.isna().sum()"]},{"cell_type":"markdown","id":"c67c220f","metadata":{"id":"c67c220f"},"source":["Now rest of the Nas can be dropped as that station might not have data collected in the time period and the data needs to be normalized.\n","\n","😈 **Question 5:** What risks might arise if normalization is applied *before* handling missing values?\n"]},{"cell_type":"code","execution_count":10,"id":"079160de","metadata":{"id":"079160de","outputId":"09df8c53-703d-4022-8070-f8ea62827513","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1750783904700,"user_tz":-120,"elapsed":65,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["longitude       0\n","latitude        0\n","station_code    0\n","datetime        0\n","temp            0\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>longitude</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>latitude</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>station_code</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>datetime</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>temp</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":10}],"source":["dataframes = dataframes.dropna()\n","dataframes.isna().sum()"]},{"cell_type":"code","execution_count":11,"id":"e2b6ef96","metadata":{"id":"e2b6ef96","outputId":"04e26970-71f6-40eb-89ea-ccc91bafee8a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750783908311,"user_tz":-120,"elapsed":13,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(359184, 5)"]},"metadata":{},"execution_count":11}],"source":["dataframes.shape"]},{"cell_type":"markdown","id":"3618005c","metadata":{"id":"3618005c"},"source":["## Staged data loading (Housekeeping)\n","\n","Finally, and before we want to perform any analysis of the data, we will store the \"cleaned\" dataset for later re-use. Subsequent notebooks can then easily reload the \"raw_data\" from the local storage or your mounted google drive folder when needed."]},{"cell_type":"code","execution_count":12,"id":"e6e51c3f","metadata":{"id":"e6e51c3f","executionInfo":{"status":"ok","timestamp":1750783919059,"user_tz":-120,"elapsed":5144,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[],"source":["dataframes.to_csv(os.path.join(TIMESERIES_DATA_DIR, \"raw_data.csv\"), index=False)"]},{"cell_type":"markdown","id":"838444Ie5Lsr","metadata":{"id":"838444Ie5Lsr"},"source":["😈 **Task 6:** Re-inspect the code above and reflect on the data management strategy employed here. What happens if you re-run the script after changing station codes or variables? Would the notebook repeat all download operations if you add a single station or variable? What could you do to improve this workflow?\n","\n","Don't waste time by trying to build the ultimate do-it-all dataloader - you can attend my lecture on Earth System Data Processing if you are keen to go deeper down this route."]},{"cell_type":"markdown","id":"45c18223","metadata":{"id":"45c18223"},"source":["### Leftovers from first cleanup\n","\n","\n","Below cell can be used to reload data if using an open source notebook servers like google colab and the if the usage limit is reached or for other issues"]},{"cell_type":"code","execution_count":13,"id":"626bfaba","metadata":{"id":"626bfaba","outputId":"8fad3e18-52fb-4b88-f1c8-bd277ec03cf5","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1750783999891,"user_tz":-120,"elapsed":8521,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   longitude   latitude station_code                  datetime  temp\n","0   7.567796  47.819182      DEBW073 1997-01-01 00:00:00+00:00 -10.0\n","1   7.567796  47.819182      DEBW073 1997-01-01 01:00:00+00:00 -11.0\n","2   7.567796  47.819182      DEBW073 1997-01-01 02:00:00+00:00 -11.0\n","3   7.567796  47.819182      DEBW073 1997-01-01 03:00:00+00:00 -12.0\n","4   7.567796  47.819182      DEBW073 1997-01-01 04:00:00+00:00 -12.0"],"text/html":["\n","  <div id=\"df-b692cd88-cdde-404e-80ac-09e89a3946c7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>station_code</th>\n","      <th>datetime</th>\n","      <th>temp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7.567796</td>\n","      <td>47.819182</td>\n","      <td>DEBW073</td>\n","      <td>1997-01-01 00:00:00+00:00</td>\n","      <td>-10.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7.567796</td>\n","      <td>47.819182</td>\n","      <td>DEBW073</td>\n","      <td>1997-01-01 01:00:00+00:00</td>\n","      <td>-11.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7.567796</td>\n","      <td>47.819182</td>\n","      <td>DEBW073</td>\n","      <td>1997-01-01 02:00:00+00:00</td>\n","      <td>-11.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7.567796</td>\n","      <td>47.819182</td>\n","      <td>DEBW073</td>\n","      <td>1997-01-01 03:00:00+00:00</td>\n","      <td>-12.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.567796</td>\n","      <td>47.819182</td>\n","      <td>DEBW073</td>\n","      <td>1997-01-01 04:00:00+00:00</td>\n","      <td>-12.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b692cd88-cdde-404e-80ac-09e89a3946c7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b692cd88-cdde-404e-80ac-09e89a3946c7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b692cd88-cdde-404e-80ac-09e89a3946c7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-92a42676-d56c-40de-a5d1-e76dcbd3b55e\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92a42676-d56c-40de-a5d1-e76dcbd3b55e')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-92a42676-d56c-40de-a5d1-e76dcbd3b55e button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"dataframes"}},"metadata":{},"execution_count":13}],"source":["import pandas as pd\n","import os\n","\n","## Raw data csv is also made available for the select stations in URL:\n","url = \"https://drive.google.com/uc?export=download&id=1cmTTWY3f18SikgRBcZzhtFswIf7XwPJq\"\n","dataframes = pd.read_csv(url,parse_dates=[\"datetime\"])\n","## Else if using local files:\n","# dataframes = pd.read_csv(os.path.join(TIMESERIES_DATA_DIR, \"raw_data.csv\"))\n","dataframes.head()"]},{"cell_type":"code","execution_count":14,"id":"b9d4b72a","metadata":{"id":"b9d4b72a","outputId":"b7e4d8d0-5f8e-4fb5-aa84-0f93b9ca57fa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750784002870,"user_tz":-120,"elapsed":11,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(579480, 5)"]},"metadata":{},"execution_count":14}],"source":["dataframes.shape"]},{"cell_type":"code","execution_count":15,"id":"44b4e968","metadata":{"id":"44b4e968","outputId":"a08aa43d-c051-490b-9bb1-614f2ef34170","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1750784003648,"user_tz":-120,"elapsed":56,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["longitude       0\n","latitude        0\n","station_code    0\n","datetime        0\n","temp            0\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>longitude</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>latitude</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>station_code</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>datetime</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>temp</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":15}],"source":["dataframes.isna().sum()"]},{"cell_type":"markdown","id":"5ZLNbEWgo7c0","metadata":{"id":"5ZLNbEWgo7c0"},"source":["### (Optional/Advanced) Multi-Variable Case:\n","\n","We've seen how to download one variable for multiple stations. Now let's try and download multi-variables for one station.  "]},{"cell_type":"markdown","id":"r8CVdDesp9bq","metadata":{"id":"r8CVdDesp9bq"},"source":["- You know the drill at this point:\n","  - Set the paths for loading the timeseries_ids(unique to each variable) corresponding to the station code and downloading timeseries data for all the variables.\n","  - Fetch the variables for the station of interest\n","  - Fill the gaps upto 6hrs\n","  - Drop NAs\n"]},{"cell_type":"markdown","id":"tVyo57nMqOd4","metadata":{"id":"tVyo57nMqOd4"},"source":["#### Fetch the variables"]},{"cell_type":"code","execution_count":null,"id":"Mk8UUqZOqN05","metadata":{"id":"Mk8UUqZOqN05"},"outputs":[],"source":["# Let us focus on one single station\n","station_codes = [\"DENW094\"]\n","variable_columns = [\"no2\", \"temp\", \"o3\", \"no\", \"press\"]\n","\n","# Note: the TOAR API sets limits to anonymous users; you can download max 3 timeseries with one request.\n","# Hence, you will need to adapt this code to load data of all 5 variables.\n"]},{"cell_type":"markdown","id":"FvPc3lp8aoN9","metadata":{"id":"FvPc3lp8aoN9"},"source":["</details>"]},{"cell_type":"markdown","id":"BBpWNtA2pX5K","metadata":{"id":"BBpWNtA2pX5K"},"source":["#### Download the variables data for that 1 station via REST API"]},{"cell_type":"code","execution_count":null,"id":"yIGfmD85pMF7","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":501},"id":"yIGfmD85pMF7","outputId":"f69a57a6-3ef4-4cc6-b110-d7038f759867"},"outputs":[{"name":"stdout","output_type":"stream","text":["\t\tStation DENW094 is already processed, skipping.\n","\t Number of time series meta data fetched : 5\n","\tCSV already exists for timeseries ID 73, skipping download.\n","Dataframe for timeseries ID 73 loaded successfully with shape (210619, 9)\n","Station ['DENW094'] min time: 1999-07-02 18:00:00+00:00, max time: 2025-05-30 07:00:00+00:00, hours between: 227125.00\n","\tCSV already exists for timeseries ID 74, skipping download.\n","Dataframe for timeseries ID 74 loaded successfully with shape (209675, 9)\n","Station ['DENW094'] min time: 1999-07-05 15:00:00+00:00, max time: 2025-05-30 07:00:00+00:00, hours between: 227056.00\n","\tCSV already exists for timeseries ID 75, skipping download.\n","Dataframe for timeseries ID 75 loaded successfully with shape (208155, 9)\n","Station ['DENW094'] min time: 1999-07-05 15:00:00+00:00, max time: 2025-05-30 07:00:00+00:00, hours between: 227056.00\n","\tCSV already exists for timeseries ID 76, skipping download.\n","Dataframe for timeseries ID 76 loaded successfully with shape (245896, 9)\n","Station ['DENW094'] min time: 1997-01-01 00:00:00+00:00, max time: 2025-05-30 07:00:00+00:00, hours between: 249031.00\n","\tCSV already exists for timeseries ID 80, skipping download.\n","Dataframe for timeseries ID 80 loaded successfully with shape (160608, 9)\n","Station ['DENW094'] min time: 1999-07-02 14:00:00+00:00, max time: 2023-12-31 23:00:00+00:00, hours between: 214761.00\n","\t Total dataFrames processed : 1145034 and shape of first dataframe (1145034, 9).\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>station_code</th>\n","      <th>datetime</th>\n","      <th>o3</th>\n","      <th>no2</th>\n","      <th>no</th>\n","      <th>temp</th>\n","      <th>press</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>681240</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 00:00:00+00:00</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-15.85</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>681241</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 01:00:00+00:00</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-16.35</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>681242</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 02:00:00+00:00</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-16.45</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>681243</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 03:00:00+00:00</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-17.15</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>681244</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 04:00:00+00:00</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-17.35</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        longitude   latitude station_code                  datetime  o3  no2  \\\n","681240   6.093923  50.754704      DENW094 1997-01-01 00:00:00+00:00 NaN  NaN   \n","681241   6.093923  50.754704      DENW094 1997-01-01 01:00:00+00:00 NaN  NaN   \n","681242   6.093923  50.754704      DENW094 1997-01-01 02:00:00+00:00 NaN  NaN   \n","681243   6.093923  50.754704      DENW094 1997-01-01 03:00:00+00:00 NaN  NaN   \n","681244   6.093923  50.754704      DENW094 1997-01-01 04:00:00+00:00 NaN  NaN   \n","\n","        no   temp  press  \n","681240 NaN -15.85    NaN  \n","681241 NaN -16.35    NaN  \n","681242 NaN -16.45    NaN  \n","681243 NaN -17.15    NaN  \n","681244 NaN -17.35    NaN  "]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["# Load existing timeseries IDs from json to skip calls to TOAR\n","existing_timeseries = load_existing_timeseries_ids()\n","\n","timeseries_data = fetch_timeseries_data(station_codes, existing_timeseries,variable_columns)\n","print(f\"\\t Number of time series meta data fetched : {len(timeseries_data)}\")\n","\n","# save existing timeseries IDs as json to reduce calls to TOAR in future\n","save_timeseries_ids(timeseries_data)\n","\n","dataframes = download_csv_data(timeseries_data,variable_columns)\n","print(f\"\\t Total dataFrames processed : {len(dataframes)} and shape of first dataframe {dataframes.shape}.\")\n","\n","dataframes.head()\n"]},{"cell_type":"markdown","id":"qqmumS-_pope","metadata":{"id":"qqmumS-_pope"},"source":["#### Data handling (observational gaps)"]},{"cell_type":"markdown","id":"s7xwW3dEKftO","metadata":{"id":"s7xwW3dEKftO"},"source":["##### Filling up upto 6 NAs"]},{"cell_type":"code","execution_count":18,"id":"sdTokb2GKeDH","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"sdTokb2GKeDH","outputId":"69f9a4db-0f03-4b3a-ec40-c559b502bf05","executionInfo":{"status":"ok","timestamp":1750784055638,"user_tz":-120,"elapsed":875,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["longitude       0\n","latitude        0\n","station_code    0\n","datetime        0\n","temp            0\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>longitude</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>latitude</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>station_code</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>datetime</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>temp</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":18}],"source":["dataframes[variable_columns] = dataframes.groupby(group_columns)[variable_columns].transform(fill_six_nans)\n","dataframes.isna().sum()"]},{"cell_type":"markdown","id":"3Y9nlWqmJQe2","metadata":{"id":"3Y9nlWqmJQe2"},"source":["##### After dropping NAs"]},{"cell_type":"code","execution_count":19,"id":"U5S7KBXSJOb4","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"U5S7KBXSJOb4","outputId":"322f9694-aa48-41d0-f5b4-75356898a022","executionInfo":{"status":"ok","timestamp":1750784055736,"user_tz":-120,"elapsed":13,"user":{"displayName":"A. Weitz","userId":"10514928356507497698"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["longitude       0\n","latitude        0\n","station_code    0\n","datetime        0\n","temp            0\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>longitude</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>latitude</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>station_code</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>datetime</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>temp</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":19}],"source":["dataframes = dataframes.dropna()\n","dataframes.isna().sum()"]},{"cell_type":"markdown","id":"qd4YM9V0Smu8","metadata":{"id":"qd4YM9V0Smu8"},"source":["#### Statistical Sanity Check"]},{"cell_type":"code","execution_count":null,"id":"61S7XC7zNU1y","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":647},"id":"61S7XC7zNU1y","outputId":"f5e2396b-1dba-4be0-9bef-02bbff2c6ba8"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"10\" halign=\"left\">no2</th>\n","      <th>...</th>\n","      <th colspan=\"10\" halign=\"left\">press</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","      <th>sum</th>\n","      <th>std</th>\n","      <th>var</th>\n","      <th>median</th>\n","      <th>prod</th>\n","      <th>nunique</th>\n","      <th>5th_percentile</th>\n","      <th>...</th>\n","      <th>std</th>\n","      <th>var</th>\n","      <th>median</th>\n","      <th>prod</th>\n","      <th>nunique</th>\n","      <th>5th_percentile</th>\n","      <th>10th_percentile</th>\n","      <th>25th_percentile</th>\n","      <th>50th_percentile</th>\n","      <th>75th_percentile</th>\n","    </tr>\n","    <tr>\n","      <th>station_code</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>DENW094</th>\n","      <td>-2.544249</td>\n","      <td>81.321835</td>\n","      <td>7.576288</td>\n","      <td>5.309811e+06</td>\n","      <td>6.360161</td>\n","      <td>40.451654</td>\n","      <td>5.648076</td>\n","      <td>-0.0</td>\n","      <td>289712</td>\n","      <td>1.25063</td>\n","      <td>...</td>\n","      <td>9.810325</td>\n","      <td>96.242473</td>\n","      <td>993.1915</td>\n","      <td>0.0</td>\n","      <td>170209</td>\n","      <td>975.432</td>\n","      <td>980.0</td>\n","      <td>987.046385</td>\n","      <td>993.1915</td>\n","      <td>998.9072</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 70 columns</p>\n","</div>"],"text/plain":["                   no2                                               \\\n","                   min        max      mean           sum       std   \n","station_code                                                          \n","DENW094      -2.544249  81.321835  7.576288  5.309811e+06  6.360161   \n","\n","                                                               ...     press  \\\n","                    var    median prod nunique 5th_percentile  ...       std   \n","station_code                                                   ...             \n","DENW094       40.451654  5.648076 -0.0  289712        1.25063  ...  9.810325   \n","\n","                                                                               \\\n","                    var    median prod nunique 5th_percentile 10th_percentile   \n","station_code                                                                    \n","DENW094       96.242473  993.1915  0.0  170209        975.432           980.0   \n","\n","                                                              \n","             25th_percentile 50th_percentile 75th_percentile  \n","station_code                                                  \n","DENW094           987.046385        993.1915        998.9072  \n","\n","[1 rows x 70 columns]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'min'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>no2</th>\n","      <th>temp</th>\n","      <th>o3</th>\n","      <th>no</th>\n","      <th>press</th>\n","    </tr>\n","    <tr>\n","      <th>station_code</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>DENW094</th>\n","      <td>-2.544249</td>\n","      <td>-17.35</td>\n","      <td>-1.417507</td>\n","      <td>-3.360428</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   no2   temp        o3        no  press\n","station_code                                            \n","DENW094      -2.544249 -17.35 -1.417507 -3.360428    0.0"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'max'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>no2</th>\n","      <th>temp</th>\n","      <th>o3</th>\n","      <th>no</th>\n","      <th>press</th>\n","    </tr>\n","    <tr>\n","      <th>station_code</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>DENW094</th>\n","      <td>81.321835</td>\n","      <td>39.0784</td>\n","      <td>134.83356</td>\n","      <td>447.81647</td>\n","      <td>1023.717</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    no2     temp         o3         no     press\n","station_code                                                    \n","DENW094       81.321835  39.0784  134.83356  447.81647  1023.717"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'mean'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>no2</th>\n","      <th>temp</th>\n","      <th>o3</th>\n","      <th>no</th>\n","      <th>press</th>\n","    </tr>\n","    <tr>\n","      <th>station_code</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>DENW094</th>\n","      <td>7.576288</td>\n","      <td>10.68534</td>\n","      <td>24.713563</td>\n","      <td>3.301673</td>\n","      <td>992.484116</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   no2      temp         o3        no       press\n","station_code                                                     \n","DENW094       7.576288  10.68534  24.713563  3.301673  992.484116"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'std'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>no2</th>\n","      <th>temp</th>\n","      <th>o3</th>\n","      <th>no</th>\n","      <th>press</th>\n","    </tr>\n","    <tr>\n","      <th>station_code</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>DENW094</th>\n","      <td>6.360161</td>\n","      <td>7.440747</td>\n","      <td>14.653677</td>\n","      <td>8.852862</td>\n","      <td>9.810325</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   no2      temp         o3        no     press\n","station_code                                                   \n","DENW094       6.360161  7.440747  14.653677  8.852862  9.810325"]},"metadata":{},"output_type":"display_data"}],"source":["stats = ['min', 'max', 'mean', 'sum', 'std', 'var', 'median','prod','nunique',\n","    ('5th_percentile', lambda x: x.quantile(0.05)),\n","    ('10th_percentile', lambda x: x.quantile(0.10)),\n","    ('25th_percentile', lambda x: x.quantile(0.25)),\n","    ('50th_percentile', lambda x: x.quantile(0.50)), #(median)\n","    ('75th_percentile', lambda x: x.quantile(0.75))]\n","agg_dict = {col: stats for col in variable_columns}\n","grouped = dataframes.groupby('station_code').agg(agg_dict)\n","display(grouped)\n","\n","for agg_func in ['min', 'max', 'mean', 'std']:\n","    display(agg_func)\n","    agg_view = grouped.xs(agg_func, axis=1, level=1)\n","    display(agg_view)"]},{"cell_type":"code","execution_count":null,"id":"bad453c7","metadata":{"id":"bad453c7"},"outputs":[],"source":["dataframes.to_csv(os.path.join(TIMESERIES_DATA_DIR, \"raw_data.csv\"), index=False)"]},{"cell_type":"markdown","id":"hkSc-_CdSxyZ","metadata":{"id":"hkSc-_CdSxyZ"},"source":["#### Log Scaling after checking for skewdness\n","\n","*ToDo:* This cell should be transfered to the data preparation part of the ML models.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"yNPu71utSxS2","metadata":{"id":"yNPu71utSxS2"},"outputs":[],"source":["import numpy as np\n","from scipy.stats import skew\n","\n","def log_transform_if_skewed(df, columns, threshold=1.0):\n","    \"\"\"\n","    Log-transform the specified columns of a DataFrame based on their skewdness.\n","\n","    Args:\n","        df (pd.DataFrame): The input DataFrame.\n","        columns (list): List of column names that need to be checked for skewdness.\n","\n","    Returns:\n","        pd.DataFrame: DataFrame with normalized columns.\n","    \"\"\"\n","    df_transformed = df.copy()\n","\n","    for col in columns:\n","        # s = df[col].dropna()\n","        s = df[col]\n","        current_skewness = skew(s)\n","\n","        print(f\"[{col}] Skewness: {current_skewness:.2f}\")\n","\n","        if abs(current_skewness) > threshold:\n","            # To avoid log(0) or log(negative values).\n","            if (s <= 0).any():\n","                shift = abs(s.min()) + 1e-6\n","                print(f\"Applying log(x + {shift:.6f}) to {col}\")\n","                df_transformed[col] = np.log(df[col] + shift)\n","            else:\n","                print(f\"Applying log(x) to {col}\")\n","                df_transformed[col] = np.log(df[col])\n","        else:\n","            print(f\"No transformation applied to {col}.\")\n","\n","    return df_transformed"]},{"cell_type":"code","execution_count":null,"id":"MeI64XXFXED8","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379},"id":"MeI64XXFXED8","outputId":"35d8be00-8882-49ee-9ebc-f8b6845b919a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[no2] Skewness: 1.65\n","Applying log(x + 2.544250) to no2\n","[temp] Skewness: 0.21\n","No transformation applied to temp.\n","[o3] Skewness: 0.64\n","No transformation applied to o3.\n","[no] Skewness: 8.52\n","Applying log(x + 3.360429) to no\n","[press] Skewness: -9.34\n","Applying log(x + 0.000001) to press\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>station_code</th>\n","      <th>datetime</th>\n","      <th>o3</th>\n","      <th>no2</th>\n","      <th>no</th>\n","      <th>temp</th>\n","      <th>press</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>681240</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 00:00:00+00:00</td>\n","      <td>0.0</td>\n","      <td>0.933836</td>\n","      <td>1.212069</td>\n","      <td>-15.85</td>\n","      <td>-13.815511</td>\n","    </tr>\n","    <tr>\n","      <th>681241</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 01:00:00+00:00</td>\n","      <td>0.0</td>\n","      <td>0.933836</td>\n","      <td>1.212069</td>\n","      <td>-16.35</td>\n","      <td>-13.815511</td>\n","    </tr>\n","    <tr>\n","      <th>681242</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 02:00:00+00:00</td>\n","      <td>0.0</td>\n","      <td>0.933836</td>\n","      <td>1.212069</td>\n","      <td>-16.45</td>\n","      <td>-13.815511</td>\n","    </tr>\n","    <tr>\n","      <th>681243</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 03:00:00+00:00</td>\n","      <td>0.0</td>\n","      <td>0.933836</td>\n","      <td>1.212069</td>\n","      <td>-17.15</td>\n","      <td>-13.815511</td>\n","    </tr>\n","    <tr>\n","      <th>681244</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 04:00:00+00:00</td>\n","      <td>0.0</td>\n","      <td>0.933836</td>\n","      <td>1.212069</td>\n","      <td>-17.35</td>\n","      <td>-13.815511</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        longitude   latitude station_code                  datetime   o3  \\\n","681240   6.093923  50.754704      DENW094 1997-01-01 00:00:00+00:00  0.0   \n","681241   6.093923  50.754704      DENW094 1997-01-01 01:00:00+00:00  0.0   \n","681242   6.093923  50.754704      DENW094 1997-01-01 02:00:00+00:00  0.0   \n","681243   6.093923  50.754704      DENW094 1997-01-01 03:00:00+00:00  0.0   \n","681244   6.093923  50.754704      DENW094 1997-01-01 04:00:00+00:00  0.0   \n","\n","             no2        no   temp      press  \n","681240  0.933836  1.212069 -15.85 -13.815511  \n","681241  0.933836  1.212069 -16.35 -13.815511  \n","681242  0.933836  1.212069 -16.45 -13.815511  \n","681243  0.933836  1.212069 -17.15 -13.815511  \n","681244  0.933836  1.212069 -17.35 -13.815511  "]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["dataframe_= log_transform_if_skewed(dataframes, variable_columns, threshold=1.0)\n","dataframe_.head()"]},{"cell_type":"markdown","id":"ojsWf0KrRyjr","metadata":{"id":"ojsWf0KrRyjr"},"source":["#### Normalize the data"]},{"cell_type":"markdown","id":"z7XAF2WzcI5G","metadata":{"id":"z7XAF2WzcI5G"},"source":["😈 Task 8: Why do we need both log transformation and Z-score normalization?"]},{"cell_type":"code","execution_count":null,"id":"1d2c0b47","metadata":{"id":"1d2c0b47"},"outputs":[],"source":["def standard_scaler(df, columns):\n","    \"\"\"\n","    Standardize the specified columns of a DataFrame by subtracting the mean\n","    and dividing by the standard deviation (Z-score normalization).\n","\n","    Args:\n","        df (pd.DataFrame): The input DataFrame.\n","        columns (list): List of column names to be normalized.\n","\n","    Returns:\n","        pd.DataFrame: DataFrame with normalized columns.\n","    \"\"\"\n","    df_scaled = df.copy()\n","    for col in columns:\n","        mean = df_scaled[col].mean()\n","        std = df_scaled[col].std()\n","        df_scaled[col] = (df_scaled[col] - mean) / std\n","    return df_scaled"]},{"cell_type":"code","execution_count":null,"id":"6kGKgXpsRzgk","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"6kGKgXpsRzgk","outputId":"6c98c637-07d8-4f7f-cf4d-772ff4c21ce5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>station_code</th>\n","      <th>datetime</th>\n","      <th>o3</th>\n","      <th>no2</th>\n","      <th>no</th>\n","      <th>temp</th>\n","      <th>press</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>681240</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 00:00:00+00:00</td>\n","      <td>-1.686509</td>\n","      <td>-2.140763</td>\n","      <td>-0.758096</td>\n","      <td>-3.566220</td>\n","      <td>-337.675195</td>\n","    </tr>\n","    <tr>\n","      <th>681241</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 01:00:00+00:00</td>\n","      <td>-1.686509</td>\n","      <td>-2.140763</td>\n","      <td>-0.758096</td>\n","      <td>-3.633418</td>\n","      <td>-337.675195</td>\n","    </tr>\n","    <tr>\n","      <th>681242</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 02:00:00+00:00</td>\n","      <td>-1.686509</td>\n","      <td>-2.140763</td>\n","      <td>-0.758096</td>\n","      <td>-3.646857</td>\n","      <td>-337.675195</td>\n","    </tr>\n","    <tr>\n","      <th>681243</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 03:00:00+00:00</td>\n","      <td>-1.686509</td>\n","      <td>-2.140763</td>\n","      <td>-0.758096</td>\n","      <td>-3.740934</td>\n","      <td>-337.675195</td>\n","    </tr>\n","    <tr>\n","      <th>681244</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 04:00:00+00:00</td>\n","      <td>-1.686509</td>\n","      <td>-2.140763</td>\n","      <td>-0.758096</td>\n","      <td>-3.767813</td>\n","      <td>-337.675195</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        longitude   latitude station_code                  datetime        o3  \\\n","681240   6.093923  50.754704      DENW094 1997-01-01 00:00:00+00:00 -1.686509   \n","681241   6.093923  50.754704      DENW094 1997-01-01 01:00:00+00:00 -1.686509   \n","681242   6.093923  50.754704      DENW094 1997-01-01 02:00:00+00:00 -1.686509   \n","681243   6.093923  50.754704      DENW094 1997-01-01 03:00:00+00:00 -1.686509   \n","681244   6.093923  50.754704      DENW094 1997-01-01 04:00:00+00:00 -1.686509   \n","\n","             no2        no      temp       press  \n","681240 -2.140763 -0.758096 -3.566220 -337.675195  \n","681241 -2.140763 -0.758096 -3.633418 -337.675195  \n","681242 -2.140763 -0.758096 -3.646857 -337.675195  \n","681243 -2.140763 -0.758096 -3.740934 -337.675195  \n","681244 -2.140763 -0.758096 -3.767813 -337.675195  "]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["dataframes = standard_scaler(dataframe_, variable_columns)\n","dataframes.head()"]},{"cell_type":"markdown","id":"-cc-ixdbc_QR","metadata":{"id":"-cc-ixdbc_QR"},"source":["##### Save the normalized dataframe for later use"]},{"cell_type":"code","execution_count":null,"id":"Oi3PPzzJZ5Vf","metadata":{"id":"Oi3PPzzJZ5Vf"},"outputs":[],"source":["dataframes.to_csv(os.path.join(TIMESERIES_DATA_DIR, \"normalized_data.csv\"), index=False)"]},{"cell_type":"markdown","id":"ZBg-E2YQert8","metadata":{"id":"ZBg-E2YQert8"},"source":["##### If you want the normalized data directly, then you could just download from the drive."]},{"cell_type":"code","execution_count":null,"id":"rZ4sHWj0c5ks","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"rZ4sHWj0c5ks","outputId":"9e0df20d-c721-4648-a46b-5f95c96c6fa2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>station_code</th>\n","      <th>datetime</th>\n","      <th>o3</th>\n","      <th>no2</th>\n","      <th>no</th>\n","      <th>temp</th>\n","      <th>press</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 00:00:00+00:00</td>\n","      <td>-1.686509</td>\n","      <td>-2.140763</td>\n","      <td>-0.758096</td>\n","      <td>-3.566220</td>\n","      <td>-337.675195</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 01:00:00+00:00</td>\n","      <td>-1.686509</td>\n","      <td>-2.140763</td>\n","      <td>-0.758096</td>\n","      <td>-3.633418</td>\n","      <td>-337.675195</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 02:00:00+00:00</td>\n","      <td>-1.686509</td>\n","      <td>-2.140763</td>\n","      <td>-0.758096</td>\n","      <td>-3.646857</td>\n","      <td>-337.675195</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 03:00:00+00:00</td>\n","      <td>-1.686509</td>\n","      <td>-2.140763</td>\n","      <td>-0.758096</td>\n","      <td>-3.740934</td>\n","      <td>-337.675195</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6.093923</td>\n","      <td>50.754704</td>\n","      <td>DENW094</td>\n","      <td>1997-01-01 04:00:00+00:00</td>\n","      <td>-1.686509</td>\n","      <td>-2.140763</td>\n","      <td>-0.758096</td>\n","      <td>-3.767813</td>\n","      <td>-337.675195</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   longitude   latitude station_code                   datetime        o3  \\\n","0   6.093923  50.754704      DENW094  1997-01-01 00:00:00+00:00 -1.686509   \n","1   6.093923  50.754704      DENW094  1997-01-01 01:00:00+00:00 -1.686509   \n","2   6.093923  50.754704      DENW094  1997-01-01 02:00:00+00:00 -1.686509   \n","3   6.093923  50.754704      DENW094  1997-01-01 03:00:00+00:00 -1.686509   \n","4   6.093923  50.754704      DENW094  1997-01-01 04:00:00+00:00 -1.686509   \n","\n","        no2        no      temp       press  \n","0 -2.140763 -0.758096 -3.566220 -337.675195  \n","1 -2.140763 -0.758096 -3.633418 -337.675195  \n","2 -2.140763 -0.758096 -3.646857 -337.675195  \n","3 -2.140763 -0.758096 -3.740934 -337.675195  \n","4 -2.140763 -0.758096 -3.767813 -337.675195  "]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import os\n","\n","## Normalized data csv is also made available for the select stations in URL:\n","# url = \"https://drive.google.com/uc?export=download&id=16Mjahl_vSznbXUFeD80xNbsz2eFmCeLG\"\n","# dataframes = pd.read_csv(url)\n","## Else if using local files you can load from the path as below:\n","# e.g. r\"./content/timeseries_multivariate_data/normalized_data.csv\"\n","dataframes = pd.read_csv(os.path.join(TIMESERIES_DATA_DIR, \"normalized_data.csv\"))\n","dataframes.head()"]},{"cell_type":"code","execution_count":null,"id":"3tHSnChQeO-L","metadata":{"id":"3tHSnChQeO-L"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["2588a2f2","7426db96"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.10"}},"nbformat":4,"nbformat_minor":5}